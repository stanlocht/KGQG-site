<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
    <head>
        <title>KGQG with PLMs</title>
        <meta charset="utf-8"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
        <link rel="stylesheet" href="assets/css/main.css"/>
        <noscript><link rel="stylesheet" href="assets/css/noscript.css"/></noscript>
    </head>
    <body
        class="is-preload">

        <!-- Sidebar -->
        <section id="sidebar">
            <div class="inner">
                <nav>
                    <ul>
                        <li><a href="#intro">Title page</a></li>
                        <li><a href="#one">Introduction</a></li>
                        <li><a href="#review">Previous research</a></li>
                        <li><a href="#method">Method</a></li>
                        <li><a href="#two">Results</a></li>
                        <li><a href="#three">Future work</a></li>
                        <!-- <li><a href="#four">In the media</a></li> -->
                    </ul>
                </nav>
            </div>
        </section>

        <!-- Wrapper -->
        <div
            id="wrapper">

            <!-- Home -->
            <section id="intro" class="wrapper style1 fullscreen fade-up">
                <div class="ornement-header"></div>
                <div class="inner">
                    <h1>Transf<strong>e</strong>r Le<strong>a</strong>rning for Qu<strong>e</strong>stion
                        								Gener<strong>a</strong>tion from Knowl<strong>e</strong>dge
                        								Graphs</h1>
                    <p>A thesis project by Stan Lochtenberg
                        <br><br>
                        Supervisor: Frank Nack<br>
                        External supervisor: Bas Niesink<br>
                    </p>
                    <small>
                        <i>Thesis project submitted in fulfillment of the requirements for the degree of:<br>
                            MSc Artificial Intelligence programme</i><br></small>
                    <a class="image"><img src="images/logos/uvalogo.png" height="110" style="padding-top: 20px" alt=""/></a><br>
                    <!-- <ul class="actions">
                    								<li><a href="#one" class="button scrolly">Learn more</a></li>
                    							</ul> -->
                </div>
            </section>

            <!-- Intro -->
            <section id="one" class="wrapper style2 spotlights">
                <section>
                    <a class="image"><img src="images/knowledge-graph.jpg" alt="" data-position="center center"/></a>
                    <div class="content">
                        <div class="inner">
                            <h2>What are knowledge graphs?</h2>
                            <p>Knowledge Graphs (KGs) are useful tools to describe and store knowledge in the form of relations between entities.
								 In a practical setting KGs have many use-cases. One example is KG-based question answering, where a KG is used to 
								 automatically look up information to answer user questions. To train a system like that, you need a lot of training data, in the form of questions about the particular KG, so the KG answering system can 'practice' answering these questions.
                            </p>
                        </div>
                    </div>
                </section>
                <section>
                    <a class="image"><img src="images/questions.png" alt="" data-position="top center"/></a>
                    <div class="content">
                        <div class="inner">
                            <h2>So, we need training data!</h2>
                            <p>
								To write these questions manually requires a lot of time and effort. 
								Therefore, it would be of great use if we can automate this process. Our research question is the following:
							</p>
                            <h3>How can we automatically generate questions to create training data?</h3>
                        </div>
                    </div>
                </section>
                <!-- <section>
                							<a class="image"><img src="images/paaspop.jpg" alt="" data-position="25% 25%" /></a>
                							<div class="content">
                								<div class="inner">
                									<p>An example of this type of institution is Paaspop, a music festival taking place in the Netherlands.
                										Its organizers would like to store their surveillance recordings from the surroundings of the festival,
                										to be able to analyze them in the long term with the goal of improving their logistics, in aspects like
                										crowd control or access control to the festival area. However, GDPR prevents them from doing so without
                										ensuring anonymity within the video recordings. This poses the following question:</p>
                										<h3>Is there a way to fully remove all personal data from a video, while preserving the intelligibility of the scene?
                										How could that be done?</h3> -->
            <!-- <ul class="actions">
            										<li><a href="generic.html" class="button">Learn more</a></li>
            									</ul> -->
                <!-- </div>
                							</div>
                						</section> -->
            </section>

            <!-- Literature review -->
            <section id="review" class="wrapper style3 fade-up">
                <div class="inner">
                    <h2>Previous research</h2>
                    <p>To be able to answer the question above, we first had to ask ourselves the following:</p>
                </div>
                <section id="one" class="wrapper style2 spotlights">
                    <section>
                        <a class="image"><img src="images/transformer.png" alt="" data-position="center center"/></a>
                        <div class="content">
                            <div class="inner">
                                <h3>How can we information from graphs in natural language?</h3>
                                <p>
									Much research has been conducted on extracting information from knowledge graphs. It often involves complicated 
									deep neural networks that are designed to handle the structure of graphs. <a href="https://arxiv.org/pdf/2007.08426.pdf">Ribeiro et al. (2020)</a> proposed
									a solution that took a different approach: they flattened to graphs to text and by doing this, transformed the graph-to-text task, to a text-to-text task.
									This offers the benefit that they were then able to use pre-trained language models to initiate their model that generates text from graphs. 
								</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <a class="image"><img src="images/hand.jpg" alt="" data-position="top center"/></a>
                        <div class="content">
                            <div class="inner">
                                <h3>How can we pose questions from graphs?</h3>
                                <p> Some research has been conducted to specifically generate questions from graphs, that ask for information that is contained within the graph. 
									<a href="https://arxiv.org/pdf/2004.06015.pdf">Chen et al. (2020)</a> used a dataset containing small graphs and questions, to train a model that can generate question, however their model architecture was quite complex, which sometimes resulted in unnatural questions. 


								</p>
                            </div>
                        </div>
                    </section>
                    <!-- <section>
                    							<a class="image"><img src="images/privacy_techniques.jpg" alt="" data-position="25% 25%" /></a>
                    							<div class="content">
                    								<div class="inner">
                    									<h3>How can we remove or process personal data in a video?</h3>
                    									<p>There are several existing methods for processing sensitive areas in images and videos. The most typical approach is to apply image filters, such as
                    									<a href="https://ieeexplore.ieee.org/document/7026221/" target="_blank">blurring (a), pixelating (b), warping (c)</a>, <a
                    									href="https://doi.org/10.1007/978-1-84882-301-3_8" target="_blank">morphing (d)</a>
                    									 or <a href="https://ieeexplore.ieee.org/document/6343472" target="_blank">masking (e)</a>, for processing specific regions
                    									 like human faces or license plates.
                    									As these are not the only areas displaying personal data, image filters could be applied to larger areas, such as the whole human body.
                    									We as humans, however, are capable of recognizing individuals even through these filters.</p>
                    									<p>Other approaches also involve some disadvantages for our specific use case. <a href="https://doi.org/10.1117/12.587986" target="_blank">Object removal (f)</a> would prevent us from preserving relevant information;
                    									and the <a href="https://doi.org/10.1109/CVPRW.2006.184" target="_blank">encryption of image regions (g)</a>, by means of pixels scrambling, can be reversed by using the corresponding key,
                    									meaning that GDPR would still apply.</p>
                    									<p>All these techniques have, in fact, something in common: they all manipulate the original video in some way. The problem of this approach is that,
                    									if the intention is to automate the anonymization process, the detection of sensitive areas would have to be perfect. If the detection and
                    									subsequent image processing failed for even just a single video frame, the privacy of the recorded individuals would be compromised.</p>
                    
                    								</div>
                    							</div>
                    						</section> -->
                </section>

            </section>


            <!-- Two -->
            <section id="method" class="wrapper style3 fade-up">
                <div class="inner">
                    <h2>Proposed method</h2>
                    <p>For our approach, we decided to fine-tune pre-trained language models (PLMs) on graph-question datasets. PLMs are models that take an text input, and generate some other text based on this input. To do this, they are trained on enourmous corpora of text, from which they learned to produce very naturall language, and also information about what words mean and how words to each other relate.
					</p>
					<p>We hypothesized, that we can achieve good performance on the task of generating questions from graphs by fine-tuning PLMs on graph-question datasets, because 1. they can already produce good natural sounding language, and 2. through the training on so much text they have learning how different components of the graph relate to each other, enabling them to understand the graph structure and form good questions.</p>

                    <div class="box alt">
                        <div class="row gtr-uniform">
                            <div class="col-12">
                                <span class="image fit"><img src="images/method.png" alt="High-level functioning of the method"/></span>
                            </div>
                        </div>
                    </div>
                    <p>To achieve this, we use the following procedure:</p>
                    <div class="features">
                        <section>
                            <span class="icon solid major fa-network-wired"></span>
                            <h3>Linearize graphs</h3>
                            <p> PLMs need data in text-form as their input, so we 'linearize', or flatten the graphs, by writing them down as a list of triples. </p>
                        </section>
                        <section>
                            <span class="icon solid major fa-dumbbell"></span>
                            <h3>Fine-tune pre-trained language model on the data</h3>
                            <p>We use a dataset containing small graphs and questions to 'fine-tune' the pre-trained language models. Fine-tuning means that the weights of the pre-trained model are taken as the starting point, and then we use another dataset to learn the new mapping, in this case the relations between the graphs and questions in the dataset.
                            </p>
                        </section>
                        <section>
                            <span class="icon solid major fa-search"></span>
                            <h3>Evaluate model</h3>
								Using automatic evaluation metrics as well as human evalution, i.e. a questionaire asking for the quality of the generated questions, the quality of the model's performance is judges.
                        </section>
                        <section>
                            <span class="icon solid major fa-project-diagram"></span>
                            <h3>Test trained model on large KG</h3>
								We then test the model on a graph that are not from the (test)dataset, but a graph that looks more like a graph that you would see in a productional setting.

                        </section>
                    </div>
                    <!-- <ul class="actions">
                    								<li><a href="generic.html" class="button">Learn more</a></li>
                    							</ul> -->
                </div>
            </section>

            <!-- Results -->
            <section id="two" class="wrapper style3 fade-up">
                <div class="inner">
                    <h2>Results</h2>
                    <p>
                        <span class="image right"><img src="images/gennedq.png" alt=""/></span><br>
                        As can be seen in the image, after training the model is able to produce good questions based on a small input graph from the test set.
					</p>


                    <h3>Autometic metric results</h3>
                    <p>
                        <span class="image left"><img src="images/autom.png" alt=""/></span><br>
                        
						Judging the two PLMs that we used, T5 and BART, we see that on the autometic metrics they were outperformed by previous research.
					</p><br><br>

                    <h3>Human evaluation</h3>
                    <p>
                        <span class="image right">
                            <img src="images/human.png" alt=""/>
                        </span>
						But, when we asked people to judge the predicted questions on how natural they were and on how relevent to the input graph they were, we found that our fine-tuned model (T5) outperformed the previous research.

                    </p>

                    <h3>Testing on productional KG</h3>
                    <p>
						To use our fine-tuned model on large graphs like the one below, we first had to split up the graph into smaller subgraphs, since our model was trained to only handle smaller graphs. This also allowed us to generate multiple questions for one large knowledge graph, which is useful since our goal was to produce a lot of training data for these graphs.
			
						<div class="box alt">
							<div class="row gtr-uniform">
								<div class="col-12">
									<span class="image fit"><img src="images/graph.svg" width="80%" alt=""/></span>
								</div>
							</div>
						</div>
						
						As we can see in the image below, when the model was fed one of the extracted subgraphs, it had a bit more trouble coming up with a good question. This is likely because of the fact that these graphs are formulated in a much different way than its training graphs, where the graph edged contained much more specific information instead of meta types of relations like 'value' and 'yields'<br><br>

						<div class="box alt">
							<div class="row gtr-uniform">
								<div class="col-12">
									<span class="image fit"><img src="images/subgraph.png" width="80%" alt=""/></span>
								</div>
							</div>
						</div>
						

					</p>


                </div>
            </section>

            <!-- Three -->
            <section id="three" class="wrapper style1 fade-up">
                <div class="inner">
                    <h2>Future work</h2>
                    <p>
						The model performed very well on the test dataset when evaluated for naturalness and relevancy, outperforming the previous state-of-the-art on the task.
						However, when tested on a knowledge graph out of the domain of the training data, it had trouble generating good questions.
						Future work can try to retrain the model, on graphs that are more representative for the productional graphs, to find if this will improve the performance on these kind of graphs.
                    </p>
                </div>
            </section>
        </div>

        <!-- Footer -->
        <footer id="footer" class="wrapper style1-alt">
            <div class="inner">
                <ul class="menu">
                    <li>&copy; Stan Lochtenberg, Info Support B.V., Universiteit van Amsterdam.</li>
                    <li>Modified template from
                        <a href="http://html5up.net" target="_blank">HTML5 UP</a>
                    </li>
                </ul>
            </div>
        </footer>

        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>

    </body>
</html>
